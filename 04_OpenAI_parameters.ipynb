{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI 參數設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2023-05-15\"\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "assert API_KEY, \"ERROR: Azure OpenAI Key is missing\"\n",
    "openai.api_key = API_KEY\n",
    "\n",
    "RESOURCE_ENDPOINT = os.getenv(\"OPENAI_API_BASE\")\n",
    "assert RESOURCE_ENDPOINT, \"ERROR: Azure OpenAI Endpoint is missing\"\n",
    "assert \"openai.azure.com\" in RESOURCE_ENDPOINT.lower(), \"ERROR: Azure OpenAI Endpoint should be in the form: \\n\\n\\t<your unique endpoint identifier>.openai.azure.com\"\n",
    "openai.api_base = RESOURCE_ENDPOINT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# temperature\n",
    "\n",
    "預設值 1\n",
    "\n",
    "決定採樣時的溫度 (sampling temperature)，參數值介於 0 與 2 之間。 數值越高意味著模型產生的文字內容越多樣化，對於更需要產生具備創意之文案的相關應用，可以嘗試使用 0.9，對於具有明確答案應用情境，建議嘗試使用 0 ( 使用 argmax 函數來採樣)。\n",
    "\n",
    "temperature 參數或 top_p 參數有著類似效果，但不要同時調整這兩個參數以避免無法確認內容產出的變化是因為哪一個參數調整所造成的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_openai(num_times, prompt, temperature):\n",
    "    for i in range(num_times):\n",
    "        \n",
    "        response = openai.Completion.create(\n",
    "            engine=os.getenv('DEPLOYMENT_NAME'),\n",
    "            prompt=prompt,\n",
    "            max_tokens=60,\n",
    "            temperature = temperature,\n",
    "            stop='\\n'\n",
    "        )\n",
    "        print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n"
     ]
    }
   ],
   "source": [
    "call_openai(10, '用正體中文一句話精簡回覆\\nQ:最佳的寵物是什麼?\\nA:', temperature = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完美的寵物並不存在，但是不同個體的需要不一樣，只要找到適合自己的照顧方式與寵物，給彼此充分的關\n",
      "貓狗(土法煉鋼Python建構)\n",
      "每個人的喜好不盡相同，沒有唯一最佳的寵物，重點是好好領養、照顧牠們，提供充足的食、水\n",
      "因人而異。\n",
      "沒有最佳的，因為每種寵物都有自己的特色。\n",
      "眼鏡蛇\n",
      "無法回答(僅一個字)。\n",
      "視個人需求而定。\n",
      "依照您的喜好和需求，最佳寵物因人而異，請自行選擇。 --- 例：依照您的喜好和需求，最佳寵物因\n",
      "\n"
     ]
    }
   ],
   "source": [
    "call_openai(10, '用正體中文一句話精簡回覆\\nQ:最佳的寵物是什麼?\\nA:', temperature = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# top_p\n",
    "\n",
    "預設值 1\n",
    "\n",
    "控制採樣溫度 (sampling temperature) 之外的另一種控制產生內容多樣性的參數，temperature 參數控制產生的內容之隨機性，而 top_p  則決定可供選擇的 Token 範圍有多大，top_p 參數使用 nucleus sampling 採樣方式，一般而言候選的 Token 機率依據高低會以長尾的方式分布，top_p 決定了只有多少百分比之候選 Token 應該被納入考慮，例如 top_p 參數設為 0.1 代表只有前 10% 的候選 Token 有機會被隨機選用。對於 temperature 與 top_p 參數背後所代表的意義可以參考 https://towardsdatascience.com/how-to-sample-from-language-models-682bceb97277\n",
    "\n",
    "temperature 參數或 top_p 參數有著類似效果，但不要同時調整這兩個參數以避免無法確認內容產出的變化是因為哪一個參數調整所造成的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_openai(num_times, prompt, top_p):\n",
    "    for i in range(num_times):\n",
    "        \n",
    "        response = openai.Completion.create(\n",
    "            engine=os.getenv('DEPLOYMENT_NAME'),\n",
    "            prompt=prompt,\n",
    "            max_tokens=60,\n",
    "            top_p = top_p,\n",
    "            stop='\\n'\n",
    "        )\n",
    "        print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "沒有最棒的寵物，每種寵物都有各自的特色。\n",
      "沒有，每個寵物都有他的獨特之處。\n",
      "因人而異，適合自己的才是最好的。 \n",
      "以主人的喜好或生活環境為準，最適合並且可以負責養育的才是最佳的寵物。 英文回覆:The best pet\n",
      "沒有一個絕對的答案，最適合自己和生活方式的才是最好的。\n",
      "依據需要而定。\n",
      "因人而異，無法一概而論\n",
      "依個人喜好而定。\n",
      "貓咪與狗狗都是很好的萌寵。\n",
      "沒有最佳寵物,每種寵物都有其值得飼養的優點。\n"
     ]
    }
   ],
   "source": [
    "call_openai(10, '用正體中文一句話精簡回覆\\nQ:最佳的寵物是什麼?\\nA:', top_p = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n"
     ]
    }
   ],
   "source": [
    "call_openai(10, '用正體中文一句話精簡回覆\\nQ:最佳的寵物是什麼?\\nA:', top_p = 0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n\n",
    "\n",
    "預設值 1\n",
    "\n",
    "為每個提示 (prompt) 產生多少個自動完成的回應內容。\n",
    "\n",
    "請注意：由於此參數會生成多個回應內容，因此它會快速消耗 Token 配額。 請謹慎使用並確認有設定妥 max_tokens 參數與停止產生內容的 stop 字串。本範例嘗試使用 gpt-35-turbo 與 gpt-4 方支援的 ChatCompletion API 來進行自動完成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "寵物的品種並非最重要，最佳的寵物是一個忠心耿耿的伴侶。\n",
      "這取決於個人喜好。\n",
      "寵物因人而異，沒有絕對的最佳寵物。\n"
     ]
    }
   ],
   "source": [
    "response  = openai.ChatCompletion.create( \n",
    "  engine = os.getenv('DEPLOYMENT_NAME'),  \n",
    "  messages = [ \n",
    "    {'role': 'user', 'content': \"用正體中文一句話精簡回覆\\nQ:最佳的寵物是什麼?\\nA:\"      \n",
    "    }\n",
    "  ],\n",
    "  n=3, # 產生三個自動完成的回覆\n",
    "  temperature=0.6,\n",
    "  max_tokens=200\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])    \n",
    "print(response['choices'][1]['message']['content'])     \n",
    "print(response['choices'][2]['message']['content'])   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logprobs\n",
    "\n",
    "預設值 null\n",
    "\n",
    "logprobs 會列出最有可能的 Token 以及其他候選之 Token 的機率。 例如如果 logprobs 設為 5，則 API 呼叫後將會回傳 5 個最可能 Token 的清單。 API 仍將傳會機率最高的 Token。 logprobs 的最大值為 5。如果您需要更高的參數值，請聯繫微軟技術支援中心以便讓微軟了解您的需求。由於 gpt5-turbo-3 與 gpt-4 模型已經不再支援 logprobs 參數，本範例仍使用 text-davinci-003 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That depends on the pet and the owner's preference\n",
      "[<OpenAIObject at 0x1ec186ae630> JSON: {\n",
      "  \"That\": -0.8687504,\n",
      "  \"The\": -1.7687309\n",
      "}, <OpenAIObject at 0x1ec186ae090> JSON: {\n",
      "  \" depends\": -0.65903336,\n",
      "  \" really\": -0.858195\n",
      "}, <OpenAIObject at 0x1ec186ad550> JSON: {\n",
      "  \" entirely\": -3.9665174,\n",
      "  \" on\": -0.023734413\n",
      "}, <OpenAIObject at 0x1ec186ae8d0> JSON: {\n",
      "  \" personal\": -1.4807402,\n",
      "  \" the\": -0.7061696\n",
      "}, <OpenAIObject at 0x1ec186ae930> JSON: {\n",
      "  \" individual\": -1.2972732,\n",
      "  \" pet\": -0.69998693\n",
      "}, <OpenAIObject at 0x1ec186ae150> JSON: {\n",
      "  \" and\": -0.13035342,\n",
      "  \"!\": -3.034318\n",
      "}, <OpenAIObject at 0x1ec186ae510> JSON: {\n",
      "  \" its\": -2.3742461,\n",
      "  \" the\": -0.1815296\n",
      "}, <OpenAIObject at 0x1ec186aebd0> JSON: {\n",
      "  \" owner\": -0.9856221,\n",
      "  \" person\": -1.4627779\n",
      "}, <OpenAIObject at 0x1ec186aecf0> JSON: {\n",
      "  \"'s\": -0.26141384,\n",
      "  \".\": -1.998791\n",
      "}, <OpenAIObject at 0x1ec186aed50> JSON: {\n",
      "  \" preference\": -0.8667084,\n",
      "  \" preferences\": -0.8938538\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "            engine= 'text-davinci-003', # 必須使用 GPT-3 模型\n",
    "            prompt='Q:What is the best pet name?\\nA:',\n",
    "            max_tokens=10,\n",
    "            temperature = 0,\n",
    "            logprobs=2,\n",
    "            stop='\\n'\n",
    "        )\n",
    "# 顯示完整回應內容\n",
    "print(response['choices'][0]['text'])\n",
    "# 顯示機率最高的 2 個英文字清單\n",
    "print(response['choices'][0]['logprobs'][\"top_logprobs\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# max_tokens\n",
    "\n",
    "預設值 無上限\n",
    "\n",
    "生成內容允許之 token 數上限。此外包含提示 (prompt) 耗用的 token 數與生成內容耗用的 token 之數總和不能超過所選用模型允許之 token 數上限。\n",
    "\n",
    "# stop\n",
    "\n",
    "預設值 null\n",
    "\n",
    "讓自動完成 API 停止產生語句的特定字串，只要遇到此參數指定的字串就會結束內容生成，最多可以設定 4 組 Stop 字串。\n",
    "\n",
    "# presence_penalty\n",
    "\n",
    "預設值 0\n",
    "\n",
    "參數值可介於 -2.0 和 2.0 之間的數字，數值大於 0 的設定值會開始在取樣時懲罰使用過的 token，也就是增加產生新的語句或新的主題之可能性。\n",
    "\n",
    "# frequency_penalty\n",
    "\n",
    "預設值 0\n",
    "\n",
    "參數值可介於 -2.0 和 2.0 之間的數字。數值大於 0 的設定值會開始在產生的文本中已經出現過的詞彙時在取樣時進行懲罰，進而降低模型產生重複詞彙的可能性。presence_penalty 參數與 frequency_penalty 參數之間的區別很微妙，frequency_penalty 可以視為控制單詞重複的方法，而將 presence_penalty 視為避免模型產生重複的主題。\n",
    "\n",
    "# stream\n",
    "\n",
    "預設值 false\n",
    "\n",
    "OpenAI 自動完成 API 預設是整個生成內容完成後才會回傳結果，如果您生成內容的時間很長，用戶等待時間就會很久。當 stream 參數設為 true 時，可以在內容生成時以串流 (stream) 方式將目前生成的最新字句立即傳送回來，相關範例可參閱 [OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_stream_completions.ipynb)\n",
    "\n",
    "\n",
    "# best_of\n",
    "\n",
    "預設值 1\n",
    "\n",
    "依據參數值在伺服器端生成多個自動完成的結果，將 \"最佳\" 的結果回傳，當設定值大於 1 的就無法啟用與使用 streame 功能。若 best_of 參數與 n 參數一起使用時，best_of 決定了有多少個候選生成出來的內容數量，n 則決定了最終回傳幾個生成的內容數量，也因 best_of 參數值必須大於 n 的參數值。 此外 gpt-35-turbo 與 gpt-4 模型已經不再支援 best_of 參數。\n",
    "請注意：由於此參數會生成多個回應內容，因此它會快速消耗 Token 配額。 請謹慎使用並確認有設定妥 max_tokens 參數與停止產生內容的 stop 字串。\n",
    "\n",
    "\n",
    "# logit_bias\n",
    "\n",
    "預設值 null\n",
    "\n",
    "修改特定 tokens 出現在自動生成 (completion) 產生之文句中的可能性。OpenAI GPT 模型每個字代表之絕對為一之 token ID 是多少? 則可利用　https://platform.openai.com/tokenizer　查詢查詢得知\n",
    "\n",
    "利用 JSON 格式來設定特定 token ID 與配套之 -100 之間 100 數值，數值 -100 表示絕對不會產生出該 token ID 所代表的字。\n",
    "\n",
    "例如您可以設定參數值 {\"16108\": -100} 來避免 token ID 為 50256 所代表的字 \"Apple\" 被模型產生出來。\n",
    "\n",
    "參考資料 : [OpenAI API Reference](https://platform.openai.com/docs/api-reference/completions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py310_sdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2139c70ac98f3202d028164a545621647e07f47fd6f5d8ac55cf952bf7c15ed1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
