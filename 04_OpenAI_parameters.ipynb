{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI 參數設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2023-05-15\"\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"<您的 API 鍵值>\").strip()\n",
    "assert API_KEY, \"ERROR: Azure OpenAI Key is missing\"\n",
    "openai.api_key = API_KEY\n",
    "\n",
    "RESOURCE_ENDPOINT = os.getenv(\"OPENAI_API_BASE\",\"https://<您的 Azure OpenAI 資源名稱>.openai.azure.com/\").strip()\n",
    "assert RESOURCE_ENDPOINT, \"ERROR: Azure OpenAI Endpoint is missing\"\n",
    "assert \"openai.azure.com\" in RESOURCE_ENDPOINT.lower(), \"ERROR: Azure OpenAI Endpoint should be in the form: \\n\\n\\t<your unique endpoint identifier>.openai.azure.com\"\n",
    "openai.api_base = RESOURCE_ENDPOINT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# temperature\n",
    "\n",
    "預設值 1\n",
    "\n",
    "決定採樣時的溫度 (sampling temperature)，參數值介於 0 與 2 之間。 數值越高意味著模型產生的文字內容越多樣化，對於更需要產生具備創意之文案的相關應用，可以嘗試使用 0.9，對於具有明確答案應用情境，建議嘗試使用 0 ( 使用 argmax 函數來採樣)。\n",
    "\n",
    "temperature 參數或 top_p 參數有著類似效果，但不要同時調整這兩個參數以避免無法確認內容產出的變化是因為哪一個參數調整所造成的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_openai(num_times, prompt, temperature):\n",
    "    for i in range(num_times):\n",
    "        \n",
    "        response = openai.Completion.create(\n",
    "            engine=os.getenv('DEPLOYMENT_NAME','gpt-35-turbo'),\n",
    "            prompt=prompt,\n",
    "            max_tokens=60,\n",
    "            temperature = temperature,\n",
    "            stop='\\n'\n",
    "        )\n",
    "        print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n"
     ]
    }
   ],
   "source": [
    "call_openai(10, '用正體中文一句話精簡回覆\\nQ:最佳的寵物是什麼?\\nA:', temperature = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 依據每個人的興趣不同而定\n",
      "最佳的寵物，是你能夠照顧好的那一隻寵物。\n",
      "沒有最佳寵物，因為每個人對於寵物的需求和偏好都不同。\n",
      "沒有最佳的寵物，沒有必要找出最佳，重要的是自己和寵物之間的感情是否和諧。\n",
      "沒有最佳的寵物，只有最適合的寵物。\n",
      "沒有最棒的寵物，因為每個人得到寵物的原因和目的都不同。詳見筆者的《養寵物首先要有心理準備》\n",
      "沒有絕對的最佳寵物,只要是適合自己生活方式、經濟條件與個性特質,能得到主人照顧與關\n",
      "依據個人與寵物的相處狀況定，沒有絕對的最佳寵物，以貓狗雙方都比較友善人類的\n",
      "視需求而定。\n",
      "視飼主生活型態而定，且幫助主人舒緩壓力，提高身心健康等等各有特色寵物，請斟酌再決\n"
     ]
    }
   ],
   "source": [
    "call_openai(10, '用正體中文一句話精簡回覆\\nQ:最佳的寵物是什麼?\\nA:', temperature = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# top_p\n",
    "\n",
    "預設值 1\n",
    "\n",
    "控制採樣溫度 (sampling temperature) 之外的另一種控制產生內容多樣性的參數，temperature 參數控制產生的內容之隨機性，而 top_p  則決定可供選擇的 Token 範圍有多大，top_p 參數使用 nucleus sampling 採樣方式，一般而言候選的 Token 機率依據高低會以長尾的方式分布，top_p 決定了只有多少百分比之候選 Token 應該被納入考慮，例如 top_p 參數設為 0.1 代表只有前 10% 的候選 Token 有機會被隨機選用。對於 temperature 與 top_p 參數背後所代表的意義可以參考 https://towardsdatascience.com/how-to-sample-from-language-models-682bceb97277\n",
    "\n",
    "temperature 參數或 top_p 參數有著類似效果，但不要同時調整這兩個參數以避免無法確認內容產出的變化是因為哪一個參數調整所造成的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_openai(num_times, prompt, top_p):\n",
    "    for i in range(num_times):\n",
    "        \n",
    "        response = openai.Completion.create(\n",
    "            engine=os.getenv('DEPLOYMENT_NAME','gpt-35-turbo'),\n",
    "            prompt=prompt,\n",
    "            max_tokens=60,\n",
    "            top_p = top_p,\n",
    "            stop='\\n'\n",
    "        )\n",
    "        print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "各位心目中最佳寵物的類型可能不太一樣，像貓咪、汪汪等都有自己獨特的魅力。但最重要的是，我\n",
      "難以回答，因為每個人的養寵目的和個人習慣不同，需要依據自身的情況來選擇適合自\n",
      "視你自身喜好而言。\n",
      "視每個人需求而定\n",
      "依據喜好來決定!\n",
      "要看個人的需求和適合度。 \n",
      "要看主人個人喜好及生活型態，最好是依照時間、精力和經濟能力，來選擇適合的寵物品種。\n",
      "依個人喜好而定。\n",
      "寵物的最佳選擇因人而異，依據自己的個性、需求及財力來飼養適合自己的小夥伴即可。 \n",
      "視寵物飼主的生活型態和個人習慣而定。\n"
     ]
    }
   ],
   "source": [
    "call_openai(10, '用正體中文一句話精簡回覆\\nQ:最佳的寵物是什麼?\\nA:', top_p = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n",
      "沒有最佳的寵物，只有最適合自己的寵物。\n"
     ]
    }
   ],
   "source": [
    "call_openai(10, '用正體中文一句話精簡回覆\\nQ:最佳的寵物是什麼?\\nA:', top_p = 0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n\n",
    "\n",
    "預設值 1\n",
    "\n",
    "為每個提示 (prompt) 產生多少個自動完成的回應內容。\n",
    "\n",
    "請注意：由於此參數會生成多個回應內容，因此它會快速消耗 Token 配額。 請謹慎使用並確認有設定妥 max_tokens 參數與停止產生內容的 stop 字串。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "取決於你的個人喜好和生活方式，沒有一個絕對的答案。但狗和貓是最受歡迎的寵物選擇之一。\n",
      "依據個人的喜好而定。\n",
      "視乎個人喜好，最佳寵物應該是能陪伴你、讓你開心的。\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "            engine=os.getenv('DEPLOYMENT_NAME','gpt-35-turbo'),\n",
    "            prompt='用正體中文一句話精簡回覆\\nQ:最佳的寵物是什麼?\\nA:',\n",
    "            max_tokens=200,\n",
    "            temperature = 0.6,\n",
    "            n=3,\n",
    "            stop='\\n'\n",
    "        )\n",
    "\n",
    "for c in response['choices']:\n",
    "    print(c['text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logprobs\n",
    "\n",
    "預設值 null\n",
    "\n",
    "logprobs 會列出最有可能的 Token 以及其他候選之 Token 的機率。 例如如果 logprobs 設為 5，則 API 呼叫後將會回傳 5 個最可能 Token 的清單。 API 仍將傳會機率最高的 Token。 logprobs 的最大值為 5。如果您需要更高的參數值，請聯繫微軟技術支援中心以便讓微軟了解您的需求。由於 gpt5-turbo-3 與 gpt-4 模型已經不再支援 logprobs 參數，本範例仍使用 text-davinci-003 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That depends on the pet and the owner's preference\n",
      "[<OpenAIObject at 0x24d15c7ee10> JSON: {\n",
      "  \"That\": -0.86744076,\n",
      "  \"The\": -1.7690787\n",
      "}, <OpenAIObject at 0x24d15c7ee70> JSON: {\n",
      "  \" depends\": -0.69307214,\n",
      "  \" really\": -0.82015115\n",
      "}, <OpenAIObject at 0x24d15c7eed0> JSON: {\n",
      "  \" entirely\": -3.9755418,\n",
      "  \" on\": -0.023513798\n",
      "}, <OpenAIObject at 0x24d15c7ef30> JSON: {\n",
      "  \" personal\": -1.4846526,\n",
      "  \" the\": -0.70668334\n",
      "}, <OpenAIObject at 0x24d15c7d730> JSON: {\n",
      "  \" individual\": -1.3026557,\n",
      "  \" pet\": -0.6972519\n",
      "}, <OpenAIObject at 0x24d15c7d250> JSON: {\n",
      "  \" and\": -0.1288854,\n",
      "  \"!\": -3.0461826\n",
      "}, <OpenAIObject at 0x24d15c7d850> JSON: {\n",
      "  \" its\": -2.3637626,\n",
      "  \" the\": -0.18220606\n",
      "}, <OpenAIObject at 0x24d15c7d790> JSON: {\n",
      "  \" owner\": -0.9770762,\n",
      "  \" person\": -1.4634519\n",
      "}, <OpenAIObject at 0x24d15c7e270> JSON: {\n",
      "  \"'s\": -0.26357746,\n",
      "  \".\": -1.9941835\n",
      "}, <OpenAIObject at 0x24d15c7e390> JSON: {\n",
      "  \" preference\": -0.8672373,\n",
      "  \" preferences\": -0.8947165\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "            engine=os.getenv('DEPLOYMENT_NAME','text-davinci-003'),\n",
    "            prompt='Q:What is the best pet name?\\nA:',\n",
    "            max_tokens=10,\n",
    "            temperature = 0,\n",
    "            logprobs=2,\n",
    "            stop='\\n'\n",
    "        )\n",
    "# 顯示完整回應內容\n",
    "print(response['choices'][0]['text'])\n",
    "# 顯示機率最高的 2 個英文字清單\n",
    "print(response['choices'][0]['logprobs'][\"top_logprobs\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# max_tokens\n",
    "\n",
    "預設值 無上限\n",
    "\n",
    "生成內容允許之 token 數上限。此外包含提示 (prompt) 耗用的 token 數與生成內容耗用的 token 之數總和不能超過所選用模型允許之 token 數上限。\n",
    "\n",
    "# stop\n",
    "\n",
    "預設值 null\n",
    "\n",
    "讓自動完成 API 停止產生語句的特定字串，只要遇到此參數指定的字串就會結束內容生成，最多可以設定 4 組 Stop 字串。\n",
    "\n",
    "# presence_penalty\n",
    "\n",
    "預設值 0\n",
    "\n",
    "參數值可介於 -2.0 和 2.0 之間的數字，數值大於 0 的設定值會開始在取樣時懲罰使用過的 token，也就是增加產生新的語句或新的主題之可能性。\n",
    "\n",
    "# frequency_penalty\n",
    "\n",
    "預設值 0\n",
    "\n",
    "參數值可介於 -2.0 和 2.0 之間的數字。數值大於 0 的設定值會開始在產生的文本中已經出現過的詞彙時在取樣時進行懲罰，進而降低模型產生重複詞彙的可能性。presence_penalty 參數與 frequency_penalty 參數之間的區別很微妙，frequency_penalty 可以視為控制單詞重複的方法，而將 presence_penalty 視為避免模型產生重複的主題。\n",
    "\n",
    "# stream\n",
    "\n",
    "預設值 false\n",
    "\n",
    "OpenAI 自動完成 API 預設是整個生成內容完成後才會回傳結果，如果您生成內容的時間很長，用戶等待時間就會很久。當 stream 參數設為 true 時，可以在內容生成時以串流 (stream) 方式將目前生成的最新字句立即傳送回來，相關範例可參閱 [OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_stream_completions.ipynb)\n",
    "\n",
    "\n",
    "# best_of\n",
    "\n",
    "預設值 1\n",
    "\n",
    "依據參數值在伺服器端生成多個自動完成的結果，將 \"最佳\" 的結果回傳，當設定值大於 1 的就無法啟用與使用 streame 功能。若 best_of 參數與 n 參數一起使用時，best_of 決定了有多少個候選生成出來的內容數量，n 則決定了最終回傳幾個生成的內容數量，也因 best_of 參數值必須大於 n 的參數值。 此外 gpt-35-turbo 與 gpt-4 模型已經不再支援 best_of 參數。\n",
    "請注意：由於此參數會生成多個回應內容，因此它會快速消耗 Token 配額。 請謹慎使用並確認有設定妥 max_tokens 參數與停止產生內容的 stop 字串。\n",
    "\n",
    "\n",
    "# logit_bias\n",
    "\n",
    "預設值 null\n",
    "\n",
    "修改特定 tokens 出現在自動生成 (completion) 產生之文句中的可能性。OpenAI GPT 模型每個字代表之絕對為一之 token ID 是多少? 則可利用　https://platform.openai.com/tokenizer　查詢查詢得知\n",
    "\n",
    "利用 JSON 格式來設定特定 token ID 與配套之 -100 之間 100 數值，數值 -100 表示絕對不會產生出該 token ID 所代表的字。\n",
    "\n",
    "例如您可以設定參數值 {\"16108\": -100} 來避免 token ID 為 50256 所代表的字 \"Apple\" 被模型產生出來。\n",
    "\n",
    "參考資料 : [OpenAI API Reference](https://platform.openai.com/docs/api-reference/completions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py310_sdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2139c70ac98f3202d028164a545621647e07f47fd6f5d8ac55cf952bf7c15ed1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
